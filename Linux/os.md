### 启动过程

操作系统是位于硬盘上的，而计算机的工作方式是取指执行，那么操作系统启动过程先把操作系统代码从磁盘加载到内存当中，X86 PC刚开机时CPU处于实模式(实模式寻址方式为CS:IP，CS左移4位+IP;CS、IP均为16位，则可表示的地址为20位，即1M)

1. 打开电源时，默认CS=0xFFFF;IP=0x0000;然后通过计算寻址到0xFFFF0区(ROM BIOS映射区)，开始执行这段固化的指令：首先先进行检查RAM、键盘、显示器、软硬磁盘等硬件信息是否正确，从磁盘0磁道0扇区开始读入第一个扇区(即操作系统的引导扇区boot)到内存0x7c00处，然后设置cs=0x07c0，ip=0x0000
2. 开始执行boot引导程序：首先把boot扇区256字节从0x7c00移到0x90000处，腾出空间(后面会将system模块移动到0地址)，然后跳到0x90000+300(前面的移动代码占用300)处继续顺序往下执行，通过int 0x13中断从磁盘第二扇区读取4个扇区(setup模块)读到内存0x90200中，在载入setup模块后再通过int 0x13中断从磁盘中读入system模块(OS代码)，然后转入0x9090:0x0000执行setup模块
3. 开始执行setup模块：完成os启动前的设置(获取光标位置以及硬件参数)，将system模块移到0地址处，后续运行过程中操作系统会一直存在0地址处；然后设置保护模式下的中断和寻址方式，初始化GDT内容，开启保护模式，跳到0地址system模块（保护模式下int n和cs:ip解释与实模式不同，保护模式是32位的寻址方式，最大寻址为4G，寻址方式为:根据CS查GDT表获取段基址+ip）
4. 开始执行system模块：

boot工作：读steup模块、读system模块

### System Call

操作系统接口是用于连接应用软件与操作系统，其表现形式为函数调用，这个函数是由系统提供的，所以又称系统调用。内核态与用户态的隔离是通过硬件来实现的，可以通过CS：IP的CS最低两位指导当前指令执行在什么态（0表示内核态，3表示用户态）；内核态可以访问任何数据，用户态不能访问内核数据。用户态想要进入内核态，只能通过中断指令int（int 指令会将CS中的CPL改为0，从而可以进入内核），系统调用的核心如下：

1. 用户程序中包含一段包含int中断指令的代码，通过发起中断进入内核态
2. 操作系统会有相应的中断处理函数，去获取用户想调用程序的编号
3. 操作系统根据编号执行相应的代码

+ printf：printf会调用中断并传入系统调用号，int 0x80中断的DPL在系统初始化时候设为3，所以用户态CPL=3可以进入int 0x80中断，在中断处理程序开始后立刻将CPL设置为0，从而可以访问内核态，然后通过查表寻找真正实现功能调用的函数并执行

![printf](..\image\printf.png)



![系统调用](..\image\系统调用.png)

### 进程与线程

​		线程是操作系统能够调度和执行的基本单位，在Linux中也被称之为轻量级进程。从定义中可以看出，线程它是操作系统的概念，在不同的操作系统中的实现是不同的

​		对于Linux操作系统而言，它对Thread的实现方式比较特殊。在Linux内核中，其实是没有线程的概念的，它把所有的线程当做标准的进程来实现，也就是说Linux内核，并没有为线程提供任何特殊的调度语义，也没有为线程实现特定的数据结构。取而代之的是，线程只是一个与其他进程共享某些资源的进程。每一个线程拥有一个唯一的task_struct结构，Linux内核它仅仅把线程当做一个正常的进程，或者说是轻量级进程，LWP(Lightweight processes)。

​		对于其他的操作系统而言，比如windows，线程相对于进程，只是一个提供了更加轻量、快速执行单元的抽象概念。对于Linux而言，线程只是进程间共享资源的一种方式，非常轻量。举个简单例子，假设有一个进程包含了N个线程。对于那些显示支持线程的操作系统而言，应该是存在一个进程描述符，依次轮流指向N个线程。这个进程描述符指明共享资源，包括内存空间和打开的文件，然后线程描述它们自己独享的资源。相反的是在Linux中，只有N个进程，因此有N个task_struct数据结构，只是这些数据结构的某些资源项是共享的。

​		Linux线程是进程资源共享的一种方式，而其他操作系统，线程则是一种实现轻量、快速执行单元的抽象概念或者实体。

#### CPU管理

一次CPU计算与一次IO操作耗时的比例可能是10^5：1；遇到IO操作时，可以通过切换CPU到另一个程序上，有效利用CPU（即为了有效利用CPU，采用并发），为保证程序切换回来还能正常运行，那么在切出去前就应该记录当前程序的信息（每个程序有一个存放信息的结构：PCB,Process Control Block）......那么引入“进程”(即进行中、运行中的程序)的概念来描述内存运行中的程序与静态程序(磁盘)的不一样，PCB用来记录进程的信息

> 1）进程是程序及其数据在计算机的一次运行活动，是一个运行过程，是一个动态的概念。进程的运行实体是程序，离开程序的进程没有存在的意义。而程序是一组有序的指令集合，是一种静态概念。
>
> 2）进程是程序的一次执行过程，它是动态地创建和消亡的，具有一定的生命周期，是暂时存在的；而程序则是一组代码的集合，它是永久存在的，可长期保存。
>
> 3）一个进程可以执行一个或几个程序，一个程序也可以构成多个进程。进程可以创建进程，而程序不能形成新的程序。
>
> 4）进程和程序的组成不同。从静态角度看，进程由程序、数据和进程控制块（PCB）三部分组成。而程序是一组有序的指令集合。

多进程切换：使用PCB记录进程信息，每个进程对应一个PCB，根据进程状态将PCB放入不同队列进行管理，在进行进程切换时，通过交换当前进程PCB与CPU的寄存器信息记录当前进程状态，然后调度切换到另一个程序中......在进程运行过程需要解决进程间同步与合作以及各进程的数据地址相互隔离不受影响(内存管理)

#### 线程切换

在一个进程中将指令执行与资源分开，多个线程共享资源，那么在进行切换时只需切换执行指令，而不用切换资源，这样既保留了并发的优点，又避免了进程切换的代价

+ 用户级线程切换：各线程拥有自己的TCB和栈，先切换TCB在切换栈。线程在切换前把下一条指令压入栈中，在TCB记录栈顶位置esp那么下次切换回来时就可以直接往下执行(弹栈拿指令直接执行)......以上操作可以完全在用户态实现，而不进入内核态，但是如果这些线程所属的进程被阻塞住，那么这些线程全部都会被阻塞
+ 内核级线程：用户级线程通过中断进入内核线程，在内核线程栈中记录用户栈的起止位置以及CS:PC(方便后续切回用户线程)

#### 进程状态

+ 创建状态(new) ：进程正在被创建，尚未到就绪状态。
+ 就绪状态(ready) ：进程已处于准备运⾏状态，即进程获得了除了处理器之外的⼀切所需资源，⼀旦得到处理器资源(处理器分配的时间⽚)即可运⾏。
+ 运⾏状态(running) ：进程正在处理器上上运⾏(单核 CPU 下任意时刻只有⼀个进程处于运⾏状态)。
+ 阻塞状态(waiting) ：⼜称为等待状态，进程正在等待某⼀事件⽽暂停运⾏如等待某资源为可⽤
  或等待 IO 操作完成。即使处理器空闲，该进程也不能运⾏。
+ 结束状态(terminated) ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运
  ⾏。

#### 进程间的通信⽅式

+  管道/匿名管道(Pipes) ：⽤于具有亲缘关系的⽗⼦进程间或者兄弟进程之间的通信
+ 有名管道(Names Pipes) : 匿名管道由于没有名字，只能⽤于亲缘关系的进程间通信。为了克服 这个缺点，提出了有名管道。有名管道严格遵循先进先出(first in first out)。有名管道以磁 盘⽂件的⽅式存在，可以实现本机任意两个进程通信
+ 信号(Signal) ：信号是⼀种⽐᫾复杂的通信⽅式，⽤于通知接收进程某个事件已经发⽣
+ 消息队列(Message Queuing) ：消息队列是消息的链表,具有特定的格式,存放在内存中并由消息 队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道（⽆名管道：只存在 于内存中的⽂件；命名管道：存在于实际的磁盘介质或者⽂件系统）不同的是消息队列存放在内 核中，只有在内核重启(即，操作系统重启)或者显示地删除⼀个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不⼀定要以先进先出的次序读取,也可以按 消息的类型读取.⽐ FIFO 更有优势。消息队列克服了信号承载信息量少，管道只能承载⽆格式 字 节流以及缓冲区⼤⼩受限等缺
+ 信号量(Semaphores) ：信号量是⼀个计数器，⽤于多进程对共享数据的访问，信号量的意图在 于进程间同步。这种通信⽅式主要⽤于解决与同步相关的问题并避免竞争条件
+ 共享内存(Shared memory) ：使得多个进程可以访问同⼀块内存空间，不同进程可以及时看到对 ⽅进程中对共享内存中数据的更新。这种⽅式需要依靠某种同步操作，如互斥锁和信号量等。可 以说这是最有⽤的进程间通信⽅式
+ 套接字(Sockets) : 此⽅法主要⽤于在客户端和服务器之间通过⽹络进⾏通信。套接字是⽀持 TCP/IP 的⽹络通信的基本操作单元，可以看做是不同主机之间的进程进⾏双向通信的端点，简 单的说就是通信的两⽅的⼀种约定，⽤套接字中的相关函数来完成通信过程。

####  线程间的同步的⽅式

线程同步是两个或多个共享关键资源的线程的并发执⾏。应该同步线程以避免关键的资源使 ⽤冲突。操作系统⼀般有下⾯三种线程同步的⽅式

+ 互斥量(Mutex)：采⽤互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为 互斥对象只有⼀个，所以可以保证公共资源不会被多个线程同时访问。⽐如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制
+ 信号量(Semphares) ：它允许同⼀时刻多个线程访问同⼀资源，但是需要控制同⼀时刻访问此资 源的最⼤线程数量
+ 事件(Event) :Wait/Notify：通过通知操作的⽅式来保持多线程同步，还可以⽅便的实现多线程 优先级的⽐较

#### 调度

调度需要考虑尽快结束任务（周转时间短）、用户操作尽快响应(响应时间短)、系统内耗时间少(吞吐量大)

+ 先到先服务(FCFS)调度算法 : 从就绪队列中选择⼀个最先进⼊该队列的进程为之分配资源，使 它⽴即执⾏并⼀直执⾏到完成或发⽣某事件⽽被阻塞放弃占⽤ CPU 时再重新调度
+ 短作业优先(SJF)的调度算法 : 从就绪队列中选出⼀个估计运⾏时间最短的进程为之分配资源， 使它⽴即执⾏并⼀直执⾏到完成或发⽣某事件⽽被阻塞放弃占⽤ CPU 时再重新调度（平均周转时间最短，但可能造成长作业饥饿）
+ 时间⽚轮转调度算法 : 时间⽚轮转调度是⼀种最古⽼，最简单，最公平且使⽤最⼴的算法，⼜ 称 RR(Round robin)调度。每个进程被分配⼀个时间段，称作它的时间⽚，即该进程允许运⾏的 时间
+ 多级反馈队列调度算法 ：前⾯介绍的⼏种进程调度的算法都有⼀定的局限性。如短进程优先的 调度算法，仅照顾了短进程⽽忽略了⻓进程 。多级反馈队列调度算法既能使⾼优先级的作业得 到响应⼜能使短作业（进程）迅速完成。，因⽽它是⽬前被公认的⼀种较好的进程调度算法， UNIX 操作系统采取的便是这种调度算法
+ 优先级调度 ： 为每个流程分配优先级，⾸先执⾏具有最⾼优先级的进程，依此类推。具有相同 优先级的进程以 FCFS ⽅式执⾏。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。

#### 同步与信号量

通过对信号量的访问与修改，可以让进程有序推进；如果多个进程共同修改信号量(读入寄存器、修改寄存器、写回变量)可能会引起共享数据语义错误，需要使用临界区保护信号量。即用临界区保护信号量，用信号量实现同步

```c++
struct semaphore{
    int value;	//记录资源个数
    PCB *queue; //记录等待在该信号量上的进程
}
P(semaphore s);	//消费资源
V(semaphore s);	//产生资源
```

```c++
//意为test
P(semaphore s){
    s.value--;
    if(s.value<0){
        sleep(s.queue)
    }
}
```

```c++
//意为increment
V(semaphore s){
    s.value--;
    if(s.value<=0){
        wakeup(s.queue);
    }
}
```

+ 生产者-消费者

```c++
//文件定义共享缓冲区
int fd = open("buffer.txt");
write(fd,0,sizeof(int));	//写int
write(fd,0,sizeof(int));	//写out

//信号量定义
semaphore full = 0;
semaphore empty = BUFFER_SIZE;
semaphore mutex = 1;

Producter(item){
    P(empty);
    P(mutex);
    //读入in;将item写入到in的位置上；
    V(mutex);
    V(full);
}

Consumer(){
    P(full);
    P(mutex);
    //读出out;从out位置读出item；
    V(mutex);
    V(empty);
}
```

+ 临界区：一次只允许一个进程进入的该进程的那一段代码（读写信号量的代码必须为临界区：互斥进入、有空让进、有限等待）
+ 信号量实现方式：使用开关中断保护信号量

```c++
/*信号量*/
typedef struct{
    char[] name[20];	//信号量名字
    int value;	//信号量值
    task_struct * queue;	//PCB队列
}semtable[20];

/* 打开信号量 */
sys_sem_open(char *name){
    在semtable中寻找name;
    没有找到则创建；
    返回对应的下标；
}

/* 获取信号量 */
sys_sem_wait(int sd){
    cli(); //关中断，阻止其他进程通过中断进入该模块
    if(semtable[sd].value-- <0){
        //设置自己为阻塞；
        semtable[sd].queue;  //将自己加入阻塞队列
        schedule();	//调度切换到其他进程
    }
    sti();	//开中断
}

main(){
    sd = sem_open("empty");//向操作系统申请信号量
    for(i=1 to 5){
        sem_wait(sd);	//尝试获取信号量，获取失败时会进入等待队列
        write(fd,&i,4);
    }
}
```

```c++
/* 读盘块:先给缓冲区上锁 */
bread(int dev,int block){
    struct buffer_head * bh;	//申请内存空闲缓冲区
    ll_rw_block(READ,bh);	//启动读取
    wati_on_buffer(bh);
}


lock_buffer(buffer_head * bh){
    cli();	//关中断
    //当所有进程被唤醒后会来竞争，只有一个进程竞争成功，其他进程又会进入阻塞状态
    while(bh -> b_block){
        //如果已经被上锁，就进入等待
        sleep_on(&bh -> b_wait)
    }
    bh -> b_block = 1;	//上锁
    sti();	//开中断
}

/* 队列中的每个PCB通过自己内部的tmp相连起来 */
void sleep_on(struct task_struct **p){
    struct task_struct *tmp;
    tmp = *p;  	//tmp前一个PCB
    *p = current;	//当前进程入队，p始终指向队列首部的PCB
    current->state = TASK_UNINTERRUPTIBLE;//修改自己的状态为阻塞态
    schdule();	//调度切换到其他线程
    if(tmp){
        //当该进程被唤醒时，继续唤醒后面的进程（即会唤醒所有进程）
        tmp -> state =0;  //就绪的状态为0
    }
}

/* 解锁 */
unlock_buffer(struct buffer_head *bh){
    bh ->b_block = 0;
    wake_up(&bh ->b_wait);
}
/* 唤醒 */
wake_up(struct task_struct **p){
    if(p && *p){
        //唤醒队首进程，PCB状态置0，即设为就绪状态；队首进程被唤醒后又会唤醒其他进程，即把队列中的所有进程唤醒，所有进程重新去竞争锁
        (**p).state=0;
        *p=NULL;
    }
}
```



#### 死锁处理

多个进程由于互相等待对方持有的资源而造成谁都无法执行的情况较死锁

> 互斥使用(Mutual exclusion)：资源固有属性
>
> 不可抢占(No preemption)：资源只能资源放弃
>
> 请求和保持(Hold and wait)：进程必须占有资源，再去申请
>
> 循环等待(Circular wait)：在资源分配图中存在一个环路

+ 死锁预防：破坏死锁出现的条件
  + 在进程执行前，一次性申请所需要的资源
  + 对资源类型进行排序，资源申请必须按序进行，保证不会出现环路等待
+ 死锁避免：检测每个资源请求，如果造成死锁就拒绝
  + 银行家算法[O(mn^2)]：每次请求会先判断该请求是否会引起死锁（即是否存在一个可完成的安全执行序列）
+ 死锁检测与恢复：检测到死锁出现时，让一些进程回滚，让出资源
+ 死锁忽略

### 内存管理

内存管理主要负责内存的分配与回收（malloc 函数：申请内存，free 函数：释 放内存），另外地址转换也就是将逻辑地址转换成相应的物理地址等功能也是操作系统内存管理做的事情

内存管理机制简单分为连续分配管理⽅式和⾮连续分配管理⽅式这两种。连续分配管理⽅式是指为⼀个⽤户程序分配 ⼀个连续的内存空间，常⻅的如 块式管理 。同样地，⾮连续分配管理⽅式允许⼀个程序使⽤的内存分 布在离散或者说不相邻的内存中，常⻅的如⻚式管理 和 段式管理。

+ 块式管理：远古时代的计算机操系统的内存管理⽅式。将内存分为⼏个固定⼤⼩的块，每个块 中只包含⼀个进程。如果程序运⾏需要内存的话，操作系统就分配给它⼀块，如果程序运⾏只需 要很⼩的空间的话，分配的这块内存很⼤⼀部分⼏乎被浪费了。这些在每个块中未被利⽤的空 间，我们称之为碎⽚
+ ⻚式管理：把主存分为⼤⼩相等且固定的⼀⻚⼀⻚的形式，⻚᫾⼩，相对相⽐于块式管理的划 分⼒度更⼤，提⾼了内存利⽤率，减少了碎⽚。⻚式管理通过⻚表对应逻辑地址和物理地址
+ 段式管理：⻚式管理虽然提⾼了内存利⽤率，但是⻚式管理其中的⻚实际并⽆任何实际意义。 段式管理把主存分为⼀段段的，每⼀段的空间⼜要⽐⼀⻚的空间⼩很多 。但是，最重要的是段 是有实际意义的，每个段定义了⼀组逻辑信息，例如,有主程序段 MAIN、⼦程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址
+ 段⻚式管理机制：段⻚式管理机制结合了段 式管理和⻚式管理的优点。简单来说段⻚式管理机制就是把主存先分成若⼲段，每个段⼜分成若⼲⻚， 也就是说 段⻚式管理机制 中段与段之间以及段的内部的都是离散的。

基于虚拟内存将分段和分页结合一起，要想实现虚拟内存，需要内存换入与换出机制

+ 重定位：每个程序经编译后每段程序代码的地址都是相对自己的起始位置的偏移量，重定位的最适合时机是运行时重定位（基址+偏移量），每个进程有各自的基地址，放在PCB中，在将程序置入内存时，初始化PCB中的基址，每次执行指令时首先从PCB中取出这个基地址结合偏移量计算出物理地址（地址翻译：每执行一条指令都要从逻辑地址算出物理地址）**PCB中需要放整个程序的基址**

#### 分段

把一个程序分成好几个段，每个段有各自的特点，各自的用途，分别放入内存，通过<段号，段内偏移>定位指令，寻址的时候把偏移地址加上对应的段的基址。在分段后，PCB中要放每一个段的基址，这个称为进程段表（LDT）；操作系统的进程对应的段表就是GDT表。

```java
CS（Code Segment）：代码段寄存器；
DS（Data Segment）：数据段寄存器；
SS（Stack Segment）：堆栈段寄存器；
ES（Extra Segment）：附加段寄存器。
当一个程序要执行时，就要决定程序代码、数据和堆栈各要用到内存的哪些位置，通过设定段寄存器 CS，DS，SS 来指向这些起始位置。通常是将DS固定，而根据需要修改CS。

1.代码段寄存器CS：存放当前正在运行的程序代码所在段的段基值，表示当前使用的指令代码可以从该段寄存器指定的存储器段中取得，相应的偏移值则由IP提供。 　
2， 数据段寄存器DS：指出当前程序使用的数据所存放段的最低地址，即存放数据段的段基值。 　
3， 堆栈段寄存器SS：指出当前堆栈的底部地址，即存放堆栈段的段基值。 

CS、DS就是所谓的段寄存器。一个程序往往分为好几个段。CS中保存了代码段的基地址，DS保存的是数据段的基地址，而IP中保存的是所要执行的下一条指令的地址
```

#### 分区与分页

+ 可变分区：已分配分区表+空闲分区表(**分区用于分配段的位置，用于管理虚拟内存**) 分区会造成内存碎片
  + 最佳适配：每次分配最小的
  + 最差适配：先从大空闲空间里分配

+ 分页：物理内存没有选择分区的方式，而是选择分页，针对每个段的内存请求，系统一页一页地分配给这个段（以页为单位分配的好处是一个段最多浪费不超过一页，即一个段对应多个页，每一页大小为4K）

  ```shell
  每页为4K
  mov [0x2240],%eax
  逻辑Page:0x2240/2^12 = 0x02
  逻辑offset:0x240
  通过页表先找出0x02对应的实际页框号，假设为3
  物理地址为3*4k+0x240=0x3240
  ```

  #### 多级页表与快表
  
  页表需要连续(连续可以直接通过基址+偏移量定位)，但如果将全部页表载入内存，会占用太多内存造成浪费
  
  #### 段页结合
  
  段面向用户、页面向硬件

### 设备驱动

os让外设工作起来主要有如下两步：CPU向外设发送指令，待外设完成工作会向CPU发起中断。

+ CPU向外设控制器的寄存器读写数据   
+ 控制器完成工作后向CPU发起中断请求

os为用户提供统一的接口，不同的设备对应不同的设备文件(/dev/xxx)，根据设备文件找到控制器的地址、内容格式等。任何外设都是open/read/write/close





磁盘：https://blog.csdn.net/weixin_37641832/article/details/103217311